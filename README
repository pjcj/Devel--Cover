NAME
    Devel::Cover - Code coverage metrics for Perl

SYNOPSIS
    To get coverage for an uninstalled module:

     cover -test

    or

     cover -delete
     HARNESS_PERL_SWITCHES=-MDevel::Cover make test
     cover

    To get coverage for an uninstalled module which uses Module::Build (0.26
    or later):

     ./Build testcover

    If the module does not use the t/*.t framework:

     PERL5OPT=-MDevel::Cover make test

    If you want to get coverage for a program:

     perl -MDevel::Cover yourprog args
     cover

     perl -MDevel::Cover=-db,cover_db,-coverage,statement,time yourprog args

DESCRIPTION
    This module provides code coverage metrics for Perl. Code coverage
    metrics describe how thoroughly tests exercise code. By using
    Devel::Cover you can discover areas of code not exercised by your tests
    and determine which tests to create to increase coverage. Code coverage
    can be considered as an indirect measure of quality.

    I consider this software to have an alpha status.  By that I mean that I
    reserve the right to alter the interface in a backwards incompatible
    manner without incrementing the major version number.  I specifically do
    not mean that this software is full of bugs or missing key features. 
    Although I'm making no guarantees on that front either.  In short, if
    you are looking for code coverage software for Perl, you have probably
    come to the end of your search.  For more of my opinions on this
    subject, see http://pjcj.sytes.net/notes/2007/03/14#alpha

    Code coverage data are collected using a pluggable runops function which
    counts how many times each op is executed.  These data are then mapped
    back to reality using the B compiler modules.  There is also a statement
    profiling facility which needs a better backend to be really useful. 
    This release also includes an experimental mode which replaces ops
    instead of using a pluggable runops function.  This provides a nice
    speed increase, but needs better testing before it becomes the default. 
    You probably don't care about any of this.

    The cover program can be used to generate coverage reports.

    Statement, branch, condition, subroutine, pod and time coverage
    information is reported.  Statement coverage data should be reasonable,
    although there may be some statements which are not reported.  Branch
    and condition coverage data should be mostly accurate too, although not
    always what one might initially expect.  Subroutine coverage should be
    as accurate as statement coverage.  Pod coverage comes from
    Pod::Coverage.  If Pod::Coverage::CountParents is available it will be
    used instead.  Coverage data for path coverage are not yet collected.

    The gcov2perl program can be used to convert gcov files to
    "Devel::Cover" databases.

    You may find that the results don't match your expectations.  I would
    imagine that at least one of them is wrong.

    The most appropriate mailing list on which to discuss this module would
    be perl-qa.  Discussion has migrated there from perl-qa-metrics which is
    now defunct.  See <http://lists.perl.org/showlist.cgi?name=perl-qa>.

REQUIREMENTS
    *   Perl 5.6.1 or greater.  Perl 5.8.2 or greater is recommended.

        Perl 5.7.0 is unsupported.  Perl 5.8.2 or greater is recommended. 
        Whilst Perl 5.6 should mostly work you will probably miss out on
        coverage information which would be available using a more modern
        version and will likely run into bugs in perl.  Perl 5.8.0 will give
        slightly different results to more recent versions due to changes in
        the op tree.

    *   The ability to compile XS extensions.

        This means a working compiler and make program at least.

    *   Storable and Digest::MD5

        Both are in the core in Perl 5.8.0 and above.

    *   Template and PPI::HTML or Perl::Tidy

        if you want syntax highlighted HTML reports.

    *   Pod::Coverage

        if you want Pod coverage.

    *   Test::Differences

        if the tests fail and you would like nice output telling you why.

